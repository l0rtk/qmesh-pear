# Translation Addons

This library simplifies the process of running various translation models within [`QVAC`](#glossary) runtime applications. It provides a seamless interface to load, execute, and manage translation addons, offering support for multiple data sources (called data loaders).

## Table of Contents

- [Installation](#installation)
- [Usage](#usage)
  - [1. Create DataLoader](#1-create-dataloader)
  - [2. Create the `args` object](#2-create-the-args-object)
  - [3. Create the `config` object](#3-create-the-config-object)
  - [4. Create Model Instance](#4-create-model-instance)
  - [5. Load Model](#5-load-model)
  - [6. Run the Model](#6-run-the-model)
  - [7. Unload the Model](#7-unload-the-model)
- [Quickstart Example](#quickstart-example)
- [Model Registry](#model-registry)
- [Supported Languages](#supported-languages)
- [ModelClasses and Packages](#modelclasses-and-packages)
- [Other Examples](#other-examples)
- [Glossary](#glossary)
- [Resources](#resources)
- [License](#license)

## Installation

### Prerequisites

Ensure that the [`Bare`](#glossary) Runtime is installed globally on your system. If it's not already installed, you can add it using:

```bash
npm i -g bare
```

> **Note:** Bare version must be **1.17.3 or higher**. Verify your version with:

```bash
bare -v
```

Before proceeding with the installation, please generate a **classic GitHub Personal Access Token (PAT)** with the `read:packages` scope. Once generated, add the token to your environment variables using the name `NPM_TOKEN`.

```bash
export NPM_TOKEN=your_personal_access_token
```

Next, create a `.npmrc` file in the root of your project with the following content:

```ini
@tetherto:registry=https://npm.pkg.github.com
//npm.pkg.github.com/:_authToken=${NPM_TOKEN}
```

This configuration ensures secure access to GitHub Packages when installing scoped packages.

### Installing the Package

Depending on your translation needs please choose an appropriate package from the [ModelClasses and Packages](#modelclasses-and-packages) Section and install it through `npm`. For example: 

```bash
# For translating English to Italian
npm i @tetherto/qvac-lib-infer-nmtcpp

# For translation English to Hindi 
npm i @tetherto/qvac-lib-inference-addon-mlc-indictrans2-en-indic-dist-200m-q0f32
```

## Usage

The library provides a straightforward and intuitive workflow for translating text. Irrespective of the chosen model, the workflow remains the same:


### 1. Create `DataLoader`

In QVAC, the [`DataLoader`](#glossary) class provides an interface for fetching model weights and other resources crucial for running AI Models. A `DataLoader` instance is required to successfully instantiate a `ModelClass`. We can create a [`HyperdriveDataLoader`](#glossary) using the following code.

```javascript
const HyperdriveDL = require('@tetherto/qvac-lib-dl-hyperdrive')

const hdDL = new HyperdriveDL({
  key: 'hyperdrive-key-hex', // (Required) The Hyperdrive key containing model files.
  store: corestore // (Optional) A Corestore instance. If not provided, Hyperdrive will use an in-memory store.
})
```

> **Note**: It is extremely important that you provide the correct `key` when using a `HyperdriveDataLoader`. A `DataLoader` with model weights and settings for an `en-it` translation can obviously not be utilized for doing a `de-en` translation. Please ensure that the `key` being used aligns with the model(package) installed and the translation requirement.

### 2. Create the `args` object

The `args` object contains the `DataLoader` we created in the previous step and other translation parameters that control how the translation model operates, including which languages to translate between and what performance metrics to collect. 

```javascript
// Create arguments object with loader, translation parameters, and options
const args = {
  // Required: Data loader instance
  loader: hdDL, // or fsDL

  // Required: Translation parameters
  params: {
    mode: 'full', // Model loading mode (full is recommended)
    srcLang: 'en', // Source language (ISO 639-1 code)
    dstLang: 'it' // Target language (ISO 639-1 code)
  },

  // Optional: Additional configuration
  opts: {
    stats: true // Enable performance statistics
  }
}
```

> Note: The list of supported languages for the `srcLang` and `dstLang` parameters differ from one `ModelClass` to another. Please refer to the [Supported Languages](#supported-languages) section for more details.

### 3. Create the `config` object

The `config` object tells the `ModelClass` which specific files from the `DataLoader` are needed to run the translation model. These files include model weights and various other configuration files that define vocabulary, tokenization rules, and other model-specific settings. Below is an example `config` object for the `MLCMarianOpusQ4F16` model class.

```javascript
// Define files needed by the model
const config = {
  // Model weight binary files
  weights: [
    'params_shard_0.bin',
    'params_shard_1.bin',
    'params_shard_2.bin',
    'params_shard_3.bin'
  ],

  // Model settings and vocabulary files
  settings: [
    'mlc-chat-config.json',
    'ndarray-cache.json',
    'vocab.json',
    'source.model',
    'target.model'
  ]
}
```

> Note: It is important that we provide the correct `config` object to our `ModelClass`. It is impossible for a 1B parameter model to run with 200M parameters. Please refer to the [config](config/) directory for configuration files of all available models. 

### 4. Create Model Instance

We first import the `ModelClass` from the installed package, then we instantiate the model by passing it the `args` and `config` objects. 

```javascript
const { ModelClass } = require('installed/package/name')
const model = new ModelClass(args, config)
```

For example:

```javascript
const { MLCMarianOpusQ4F16 } = require('@tetherto/qvac-lib-infer-nmtcpp-opus-q4f16')
const model = new MLCMarianOpusQ4F16(args, config)
```

### 5. Load Model

```javascript
try {
  // Basic usage
  await model.load()
} catch (error) {
  console.error('Failed to load model:', error)
}
```

### 6. Run the Model

We can perform inference on the input text using the `run()` method. This method returns a [`QVACResponse`](#glossary) object.

```javascript
try {
  // Execute translation on input text
  const response = await model.run('Hello world! Welcome to the internet of peers!')

  // Process streamed output using callback
  await response
    .onUpdate(outputChunk => {
      // Handle each new piece of translated text
      console.log(outputChunk)
    })
    .await() // Wait for translation to complete

  // Access performance statistics (if enabled with opts.stats)
  if (response.stats) {
    console.log('Translation completed in:', response.stats.totalTime, 'ms')
  }
} catch (error) {
  console.error('Translation failed:', error)
}
```

### 7. Unload the Model

```javascript
// Always unload the model when finished to free memory
try {
  await model.unload()
} catch (error) {
  console.error('Failed to unload model:', error)
}
```

### Additional Features

- **Pause and Resume:** Translation can be paused and resumed (see [`examples/pause.example.js`](examples/pause.example.js))
- **Progress Tracking:** Monitor loading progress with a callback function
- **Performance Stats:** Measure inference time with the `stats` option

For a complete working example that brings all these steps together, see the [Quickstart Example](#quickstart-example) below.

## Quickstart Example

Follow these steps to run the Quickstart Example:

### 1. Create a New Project

```bash
mkdir translation-example
cd translation-example
npm init -y 
```

### 2. Install Required Dependencies

```bash
npm i @tetherto/qvac-lib-infer-nmtcpp-opus-q4f16 @tetherto/qvac-lib-dl-hyperdrive
```

### 3. Create `example.js` and paste the following code into it

```bash
touch example.js
```

```javascript
// example.js

'use strict'

// Note: This import will depend on the addon package installed
const TranslationNmtcpp = require('..')
const HyperdriveDL = require('@tetherto/qvac-lib-dl-hyperdrive')

const text = 'La traduzione automatica ha rivoluzionato il modo in cui comunichiamo attraverso le barriere linguistiche nel mondo digitale moderno.'

async function main () {
  // 1. Create `DataLoader`
  const hdDL = new HyperdriveDL({
    // The hyperdrive key for en-it translation model weights and config
    key: 'hd://9ef58f31c20d5556722e0b58a5d262fd89801daf2e6cb28e3f21ac6e9228088f'
  })

  // 2. Create the `args` object
  const args = {
    loader: hdDL,
    params: { mode: 'full', dstLang: 'en', srcLang: 'it' },
    diskPath: './models',
    modelName: 'model.bin'
  }

  // 4. Create Model Instance
  const model = new TranslationNmtcpp(args, { })

  // 5. Load model
  await model.load()

  try {
    // 6. Run the Model
    const response = await model.run(text)

    await response
            .onUpdate(data => {
              console.log(data)
            })
            .await()

    console.log('translation finished!')
  } finally {
    // 7. Unload the model
    await model.unload()

    // Close the DataLoader
    await hdDL.close()
  }
}


main().catch(console.error)
```

### 4. Run the Example

```bash
bare example.js
```

You should see this output on successful execution

```bash
params_shard_0.bin has these many parameter records: 1
params_shard_1.bin has these many parameter records: 19
params_shard_2.bin has these many parameter records: 1
params_shard_3.bin has these many parameter records: 336
Ciao a tutti!
translation finished!
```

## Model Registry

The **Hyperbee key** for the model registry is:

```
8919220166add186b84c882b5f4a2c56357e02f459a20b423a3ea7826ec70781
```

Below is the section of the registry dedicated to **translation tasks**. Each entry maps a specific model and language pair (left-hand side) to the corresponding **Hyperdrive key** (right-hand side), which stores the model's weights and configuration settings.

```javascript
"indictrans:2:1B:q0f32:1.0.0:en-hi"        : "38c84fcb85bc565a617f98f48f36c1e5cf4815a04b8beb3c56bf8a4df0ce4891"
"indictrans:2:1B:q0f32:1.0.0:hi-en"        : "6dfd7b718290defeeb1d6cd37461adc6282acee118b849644f4375a46a45651c"
"indictrans:2:1B:q0f32:1.0.0:hi-hi"        : "6ab74476d55e1fe6de95fa599fcfecf72d6de8336a3d1c0548f3bef83224b565"
"dist:indictrans:2:200M:q0f32:1.0.0:en-hi" : "7d38cab3ec3efe32dba3552e830e18c9900533b4f0e7efd2d96d9bf19195853f"
"dist:indictrans:2:200M:q0f32:1.0.0:hi-en" : "120e2fa4755d3f000cb917cfccab3b5ee705a0911e31c2276050a6d6a3d6169b"
"dist:indictrans:2:320M:q0f32:1.0.0:hi-hi" : "2d618dcb2aeb4f7e80a367f9f256548807deef8bcc14de3bb52fb876c4f3fd88"
"marian:opus:::q4f16_1:1.0.0:de-en"        : "23ba293add1a0374589ce8d562fb9cd701e4ae753a186bf27b4a01e84a7a3bca"
"marian:opus:::q4f16_1:1.0.0:de-es"        : "29a9b7a0427c98d48ed391bf1f08e92f2509e3fb4479b46d5c9049cf6174143f"
"marian:opus:::q4f16_1:1.0.0:de-it"        : "157aab906c5129f1b585adfa169c9173d7256c1fe651fb4c4b162a3857c52738"
"marian:opus:::q4f16_1:1.0.0:en-de"        : "ef7976647b6cd81df1c3b5c13c49ffc61d79d9cd1ca59f94f171a8dd3b6aae8c"
"marian:opus:::q4f16_1:1.0.0:en-es"        : "bb35c4cacfb255877f9c7d44db423c3accb905e022d61f208698ca5148a2fdeb"
"marian:opus:::q4f16_1:1.0.0:en-it"        : "fc759e65aa410dc8bac52cc541643f4d47014dbbf508277fc8b5321664ebb4d8"
"marian:opus:::q4f16_1:1.0.0:es-de"        : "1c4e049eec6ee2d1b9b12e7dd7f5d7ccb5645c6a0305a6e8d48e936661387682"
"marian:opus:::q4f16_1:1.0.0:es-en"        : "5edc5fbbd859c03c5eed6206f165dfd2f34ada90e9e7bfc40761b2c9ceff0683"
"marian:opus:::q4f16_1:1.0.0:es-it"        : "f2d8adbe9a21acf1990dfd113948fbfaa7bba5c24d5e89c7cbd0713777384873"
"marian:opus:::q4f16_1:1.0.0:it-de"        : "ca7e627f62fb19221b164f9385df1f81a0fad735d9d5faa8fdc4e4f2e4dcc35c"
"marian:opus:::q4f16_1:1.0.0:it-en"        : "59e3cb84c21b356d9aef8cb084f4c2a68f182cc50e1cabee63a5ba5a6fea2cbf"
"marian:opus:::q4f16_1:1.0.0:it-es"        : "5dca3a0ca4ffe4686da0c4163b15b52be07a6676be66d1b4fb0fd9fc7aad583c"
```

Each key in this list follows the general pattern:

```
<model_family>:<version>:<size>:<quantization>:<release>:<source-lang>-<target-lang>
```

## Supported Languages

Here is the list of languages supported for the Marian models: 

<table>
  <tbody>
    <tr><td>English (en)</td></tr>
    <tr><td>German (de)</td></tr>
    <tr><td>Italian (it)</td></tr>
    <tr><td>Spanish (es)</td></tr>
  </tbody>
</table>

Here is the list of languages supported by the IndicTrans2 models:

<table>
<tbody>
  <tr>
    <td>Assamese (asm_Beng)</td>
    <td>Kashmiri (Arabic) (kas_Arab)</td>
    <td>Punjabi (pan_Guru)</td>
  </tr>
  <tr>
    <td>Bengali (ben_Beng)</td>
    <td>Kashmiri (Devanagari) (kas_Deva)</td>
    <td>Sanskrit (san_Deva)</td>
  </tr>
  <tr>
    <td>Bodo (brx_Deva)</td>
    <td>Maithili (mai_Deva)</td>
    <td>Santali (sat_Olck)</td>
  </tr>
  <tr>
    <td>Dogri (doi_Deva)</td>
    <td>Malayalam (mal_Mlym)</td>
    <td>Sindhi (Arabic) (snd_Arab)</td>
  </tr>
  <tr>
    <td>English (eng_Latn)</td>
    <td>Marathi (mar_Deva)</td>
    <td>Sindhi (Devanagari) (snd_Deva)</td>
  </tr>
  <tr>
    <td>Konkani (gom_Deva)</td>
    <td>Manipuri (Bengali) (mni_Beng)</td>
    <td>Tamil (tam_Taml)</td>
  </tr>
  <tr>
    <td>Gujarati (guj_Gujr)</td>
    <td>Manipuri (Meitei) (mni_Mtei)</td>
    <td>Telugu (tel_Telu)</td>
  </tr>
  <tr>
    <td>Hindi (hin_Deva)</td>
    <td>Nepali (npi_Deva)</td>
    <td>Urdu (urd_Arab)</td>
  </tr>
  <tr>
    <td>Kannada (kan_Knda)</td>
    <td>Odia (ory_Orya)</td>
    <td></td>
  </tr>
</tbody>
</table>

## Benchmarking

We conduct comprehensive benchmarking of our translation models to evaluate their performance across different language pairs and metrics. Our benchmarking suite measures translation quality using BLEU and COMET scores, as well as performance metrics including load times and inference speeds.

### Benchmark Results

For detailed benchmark results across all supported language pairs and model configurations, see our [Benchmark Results Summary](benchmarks/results/results_summary.md).

The benchmarking covers:

- **Translation Quality**: BLEU and COMET scores for accuracy assessment
- **Performance Metrics**: Model loading times and inference speeds
- **Language Pairs**: All supported source-target language combinations
- **Model Variants**: Different quantization levels and model sizes

Results are updated regularly as new model versions are released.

## Other Examples

- [Filesystem Data Loader](examples/example.fs.js): Demonstrates using the library with the Filesystem Data Loader for Marian model inference.
- [Pause Example](examples/pause.example.js): Demonstrates pausing and resuming the addon during inference.
- [IndicTrans2 en-hi Example](examples/indictrans.js): Demonstrates how to use the library for English-to-Hindi translation with the IndicTrans2 model, including setup, loading model weights, and running inference.

## Glossary

- **Bare** – Lightweight, modular JavaScript runtime for desktop and mobile. [Docs](https://docs.pears.com/bare-reference/overview)
- **Hyperdrive** – Secure, real-time distributed filesystem enabling P2P file sharing. [Docs](https://docs.pears.com/building-blocks/hyperdrive)
- **Hyperbee** – Decentralized B-tree built on Hypercores, with a key-value API. [Docs](https://docs.pears.com/building-blocks/hyperbee)
- **Corestore** – Factory for managing named collections of Hypercores. [Docs](https://docs.pears.com/helpers/corestore)
- **QVAC** – Open-source SDK for building decentralized AI applications.
- **QVACResponse** –  The response object used by the QVAC API. [GitHub](https://github.com/tetherto/qvac-lib-response)
- **DataLoader** – Abstraction for fetching model weights and resources. 
  Implementations include:
  - **`HyperdriveDL`** – Loads from a Hyperdrive instance [GitHub](https://github.com/tetherto/qvac-lib-dl-hyperdrive)
  - **`fsDL`** – Loads from the local filesystem [GitHub](https://github.com/tetherto/qvac-lib-dl-filesystem)

## Resources

- **Pear Platform** – Decentralized platform for deploying apps. [pears.com](https://pears.com/)
- **Bare Runtime Docs** – For running QVAC apps in a lightweight environment. [docs.pears.com/bare](https://docs.pears.com/bare-reference/overview)
- **IndicTrans2 Model** – Pretrained multilingual translation models. [AI4Bharat/IndicTrans2](https://github.com/AI4Bharat/IndicTrans2)
- **Translation App Example** – QVAC-based translation application. [qvac-examples/translation-app](https://github.com/tetherto/qvac-examples/tree/main/translation-app)

## License

This project is licensed under the Apache-2.0 License - see the [LICENSE](LICENSE) file for details.<br>
For any questions o issues, please open an issue on the GitHub repository.
Test mobile job visibility
